model_list:
  - model_name: ollama/codellama:7b-code
    litellm_params:
      model: ollama/codellama:7b-code
      api_base: "http://host.docker.internal:8001"

  - model_name: ollama/mistral
    litellm_params:
      model: ollama/mistral
      api_base: "http://host.docker.internal:8002"

  # - model_name: ollama/phi
  #   litellm_params:
  #     model: ollama/phi
  #     api_base: "http://host.docker.internal:8003"

  - model_name: gpt-3.5-turbo
    litellm_params:
      model: ollama/mistral
      api_base: "http://host.docker.internal:8003"

litellm_settings:
  drop_params: true